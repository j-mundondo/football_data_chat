{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing completed successfully\n",
      "Preprocessing completed successfully\n",
      "Preprocessing completed successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from custom_agents_LG import load_session_data, agent_executor\n",
    "from llm import get_llama_3dot3_70b_versatile,get_llama_3dot1_8b_instant,get_70b_8192\n",
    "from loaders_and_chroma_utils import vectorstore\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from typing_extensions import List, TypedDict\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing import TypedDict, List, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from typing import TypedDict, List\n",
    "from langchain_core.documents import Document\n",
    "import streamlit as st\n",
    "import os\n",
    "llm_api_key = st.secrets['GROQ_API_KEY']\n",
    "langchain_api_key = st.secrets['LANGCHAIN_API_KEY']\n",
    "llm = get_70b_8192()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\j.mundondo\\AppData\\Local\\Temp\\ipykernel_42964\\1703591915.py:20: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STEP 1: Loading document...\n",
      "Successfully split document into 11 chunks\n",
      "\n",
      "First chunk preview:\n",
      "# Relationship Between High-Intensity Activity Metrics and Injury Risk in Professional Athletes: A Longitudinal Analysis\n",
      "\n",
      "\n",
      "\n",
      "## Abstract\n",
      "\n",
      "\n",
      "\n",
      "This study investigated the relationship between high-intensi\n",
      "\n",
      "STEP 2: Clearing existing vectorstore...\n",
      "Vectorstore cleared\n",
      "\n",
      "STEP 3: Indexing document chunks...\n",
      "Added 11 chunks to vectorstore\n",
      "\n",
      "Analyzing query: What are Lee's injury risks based on his recent activity pattern?\n",
      "--------------------------------------------------\n",
      "Starting Analysis Stream:\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'llm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 266\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAnalyzing query: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m--> 266\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_player_risk_streaming\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnalysis Results:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28mprint\u001b[39m(response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Cell \u001b[1;32mIn[1], line 238\u001b[0m, in \u001b[0;36manalyze_player_risk_streaming\u001b[1;34m(question)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting Analysis Stream:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m--> 238\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mupdates\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mStep Update:\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\j.mundondo\\OneDrive - Statsports\\Desktop\\statsportsdoc\\Projects\\frequency_chat_PH\\footydata\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1670\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   1664\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[0;32m   1665\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[0;32m   1666\u001b[0m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[0;32m   1667\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[0;32m   1668\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[0;32m   1669\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[1;32m-> 1670\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1671\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1672\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1673\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1674\u001b[0m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1675\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1676\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[0;32m   1677\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1678\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\j.mundondo\\OneDrive - Statsports\\Desktop\\statsportsdoc\\Projects\\frequency_chat_PH\\footydata\\Lib\\site-packages\\langgraph\\pregel\\runner.py:231\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[0;32m    229\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 231\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_SEND\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\j.mundondo\\OneDrive - Statsports\\Desktop\\statsportsdoc\\Projects\\frequency_chat_PH\\footydata\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32mc:\\Users\\j.mundondo\\OneDrive - Statsports\\Desktop\\statsportsdoc\\Projects\\frequency_chat_PH\\footydata\\Lib\\site-packages\\langgraph\\utils\\runnable.py:462\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    458\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[0;32m    459\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    460\u001b[0m )\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 462\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Users\\j.mundondo\\OneDrive - Statsports\\Desktop\\statsportsdoc\\Projects\\frequency_chat_PH\\footydata\\Lib\\site-packages\\langgraph\\utils\\runnable.py:226\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    225\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m--> 226\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[1;32mIn[1], line 123\u001b[0m, in \u001b[0;36mextract_name_node\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_name_node\u001b[39m(state: State):\n\u001b[0;32m    122\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Node for extracting player name.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m     player_name \u001b[38;5;241m=\u001b[39m \u001b[43mextract_player_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplayer_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: player_name}\n",
      "Cell \u001b[1;32mIn[1], line 101\u001b[0m, in \u001b[0;36mextract_player_name\u001b[1;34m(question)\u001b[0m\n\u001b[0;32m     99\u001b[0m prompt \u001b[38;5;241m=\u001b[39m PromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(name_extraction_prompt)\n\u001b[0;32m    100\u001b[0m messages \u001b[38;5;241m=\u001b[39m prompt\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: question})\n\u001b[1;32m--> 101\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241m.\u001b[39minvoke(messages)\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'llm' is not defined"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from typing import TypedDict, List\n",
    "from langchain_core.documents import Document\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.document_loaders import (\n",
    "    PyPDFLoader,\n",
    "    Docx2txtLoader, \n",
    "    UnstructuredPowerPointLoader, \n",
    "    CSVLoader, \n",
    "    UnstructuredExcelLoader\n",
    ")\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "import chromadb\n",
    "\n",
    "# Initialize components\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Initialize Chroma with persistent client\n",
    "client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "vectorstore = Chroma(\n",
    "    client=client,\n",
    "    embedding_function=embedding_function,\n",
    "    collection_name=\"my_collection\"\n",
    ")\n",
    "\n",
    "# Define State class\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    player_metrics: str\n",
    "    answer: str\n",
    "    player_name: str\n",
    "\n",
    "# Document loading functions\n",
    "def load_and_split_document(file_path: str) -> List[Document]:\n",
    "    \"\"\"Load and split a document into chunks.\"\"\"\n",
    "    if file_path.endswith('.pdf'):\n",
    "        loader = PyPDFLoader(file_path)\n",
    "    elif file_path.endswith('.docx'):\n",
    "        loader = Docx2txtLoader(file_path)\n",
    "    elif file_path.endswith(('.ppt', '.pptx')):\n",
    "        loader = UnstructuredPowerPointLoader(file_path, mode=\"elements\")\n",
    "    elif file_path.endswith(('.xls', '.xlsx')):\n",
    "        loader = UnstructuredExcelLoader(file_path)\n",
    "    elif file_path.endswith('.csv'):\n",
    "        loader = CSVLoader(file_path)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file type: {file_path}\")\n",
    "\n",
    "    documents = loader.load()\n",
    "    return text_splitter.split_documents(documents)\n",
    "\n",
    "def verify_document_loading(file_path: str):\n",
    "    \"\"\"Load, index, and verify document loading with detailed debugging.\"\"\"\n",
    "    print(\"\\nSTEP 1: Loading document...\")\n",
    "    try:\n",
    "        splits = load_and_split_document(file_path)\n",
    "        print(f\"Successfully split document into {len(splits)} chunks\")\n",
    "        print(\"\\nFirst chunk preview:\")\n",
    "        if splits:\n",
    "            print(splits[0].page_content[:200])\n",
    "        \n",
    "        print(\"\\nSTEP 2: Clearing existing vectorstore...\")\n",
    "        existing_ids = vectorstore._collection.get()['ids']\n",
    "        if existing_ids:\n",
    "            vectorstore._collection.delete(ids=existing_ids)\n",
    "        print(\"Vectorstore cleared\")\n",
    "        \n",
    "        print(\"\\nSTEP 3: Indexing document chunks...\")\n",
    "        for i, split in enumerate(splits):\n",
    "            split.metadata['file_id'] = 1\n",
    "            split.metadata['chunk_id'] = i\n",
    "        \n",
    "        vectorstore.add_documents(splits)\n",
    "        print(f\"Added {len(splits)} chunks to vectorstore\")\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR during document processing: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "# Graph nodes\n",
    "def extract_player_name(question: str) -> str:\n",
    "    \"\"\"Extract player name from the question using the LLM.\"\"\"\n",
    "    name_extraction_prompt = \"\"\"\n",
    "    Extract the player name(s) from the following question. \n",
    "    If no specific player is mentioned, return None.\n",
    "    Only return the name(s) without any additional text.\n",
    "    \n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = PromptTemplate.from_template(name_extraction_prompt)\n",
    "    messages = prompt.invoke({\"question\": question})\n",
    "    response = llm.invoke(messages).content.strip()\n",
    "    \n",
    "    return response if response.lower() != \"none\" else None\n",
    "\n",
    "def get_player_metrics(player_name: str) -> dict:\n",
    "    \"\"\"Get metrics for a specific player.\"\"\"\n",
    "    return agent_executor.invoke({\n",
    "        \"input\": f\"Get {player_name}'s metrics as a dictionary format\"\n",
    "    })[\"output\"]\n",
    "\n",
    "def setup_initial_state(question: str) -> State:\n",
    "    \"\"\"Setup initial state without metrics - moved to separate node.\"\"\"\n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"context\": [],\n",
    "        \"player_metrics\": \"\",\n",
    "        \"answer\": \"\",\n",
    "        \"player_name\": \"\"\n",
    "    }\n",
    "\n",
    "def extract_name_node(state: State):\n",
    "    \"\"\"Node for extracting player name.\"\"\"\n",
    "    player_name = extract_player_name(state[\"question\"])\n",
    "    return {\"player_name\": player_name}\n",
    "\n",
    "def get_metrics_node(state: State):\n",
    "    \"\"\"Node for getting player metrics.\"\"\"\n",
    "    if not state[\"player_name\"]:\n",
    "        return {\"player_metrics\": \"No specific player mentioned in query\"}\n",
    "    \n",
    "    metrics = get_player_metrics(state[\"player_name\"])\n",
    "    return {\"player_metrics\": metrics}\n",
    "\n",
    "def retrieve_node(state: State):\n",
    "    \"\"\"Node for retrieving relevant documents.\"\"\"\n",
    "    documents = []\n",
    "    \n",
    "    if state[\"player_metrics\"] != \"No specific player mentioned in query\":\n",
    "        metrics_doc = Document(\n",
    "            page_content=f\"Current Player Metrics for {state['player_name']}:\\n{state['player_metrics']}\",\n",
    "            metadata={\"source\": \"player_metrics\"}\n",
    "        )\n",
    "        documents.append(metrics_doc)\n",
    "    \n",
    "    # Get research documents with specific queries\n",
    "    research_queries = [\n",
    "        f\"injury risk thresholds for {state['player_name']}'s activity pattern\",\n",
    "        \"critical thresholds for Dynamic Stress Load DSL\",\n",
    "        \"metabolic power thresholds for injury risk\",\n",
    "        \"recovery indicators and patterns research\",\n",
    "        \"acceleration deceleration ratio research findings\"\n",
    "    ]\n",
    "    \n",
    "    for query in research_queries:\n",
    "        retrieved_docs = vectorstore.similarity_search(\n",
    "            query,\n",
    "            k=2\n",
    "        )\n",
    "        documents.extend(retrieved_docs)\n",
    "    \n",
    "    return {\"context\": documents}\n",
    "\n",
    "def generate_node(state: State):\n",
    "    \"\"\"Generate analysis with explicit reference to research data.\"\"\"\n",
    "    if state[\"player_metrics\"] == \"No specific player mentioned in query\":\n",
    "        return {\"answer\": \"To analyze a player's injury risks, please specify a player name in your query.\"}\n",
    "    \n",
    "    # Separate metrics and research documents\n",
    "    metrics_doc = None\n",
    "    research_docs = []\n",
    "    \n",
    "    for doc in state[\"context\"]:\n",
    "        if doc.metadata.get(\"source\") == \"player_metrics\":\n",
    "            metrics_doc = doc\n",
    "        else:\n",
    "            research_docs.append(doc)\n",
    "    \n",
    "    # Format research findings\n",
    "    research_findings = \"\\n\\n\".join([\n",
    "        f\"RESEARCH FINDING {i+1}:\\n{doc.page_content}\"\n",
    "        for i, doc in enumerate(research_docs)\n",
    "    ])\n",
    "    \n",
    "    analysis_prompt = \"\"\"\n",
    "    Using ONLY the provided research data and player metrics, conduct an injury risk analysis.\n",
    "    \n",
    "    PLAYER METRICS:\n",
    "    {metrics}\n",
    "    \n",
    "    RESEARCH FINDINGS:\n",
    "    {research}\n",
    "    \n",
    "    Analyze the following aspects, citing ONLY the provided research:\n",
    "    1. Compare the player's metrics to the research thresholds\n",
    "    2. Identify specific risk factors supported by the research\n",
    "    3. Make recommendations based on the research findings\n",
    "    \n",
    "    Format your response with clear sections and evidence from the provided research.\n",
    "    \"\"\"\n",
    "    \n",
    "    messages = PromptTemplate.from_template(analysis_prompt).invoke({\n",
    "        \"metrics\": metrics_doc.page_content if metrics_doc else \"No metrics available\",\n",
    "        \"research\": research_findings\n",
    "    })\n",
    "    \n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "def build_streaming_graph():\n",
    "    \"\"\"Build graph with streaming support.\"\"\"\n",
    "    workflow = StateGraph(State)\n",
    "    \n",
    "    # Add nodes\n",
    "    workflow.add_node(\"extract_name\", extract_name_node)\n",
    "    workflow.add_node(\"get_metrics\", get_metrics_node)\n",
    "    workflow.add_node(\"retrieve\", retrieve_node)\n",
    "    workflow.add_node(\"generate\", generate_node)\n",
    "    \n",
    "    # Add edges\n",
    "    workflow.add_edge(\"extract_name\", \"get_metrics\")\n",
    "    workflow.add_edge(\"get_metrics\", \"retrieve\")\n",
    "    workflow.add_edge(\"retrieve\", \"generate\")\n",
    "    workflow.add_edge(\"generate\", END)\n",
    "    \n",
    "    # Set entry point\n",
    "    workflow.set_entry_point(\"extract_name\")\n",
    "    \n",
    "    return workflow.compile()\n",
    "\n",
    "def analyze_player_risk_streaming(question: str):\n",
    "    \"\"\"Stream the analysis process.\"\"\"\n",
    "    graph = build_streaming_graph()\n",
    "    initial_state = setup_initial_state(question)\n",
    "    \n",
    "    print(\"Starting Analysis Stream:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for step in graph.stream(initial_state, stream_mode=\"updates\"):\n",
    "        print(\"Step Update:\")\n",
    "        for key, value in step.items():\n",
    "            if key == \"context\":\n",
    "                print(f\"{key}: {len(value)} documents retrieved\")\n",
    "            else:\n",
    "                print(f\"{key}: {value}\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    return graph.invoke(initial_state)\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # First load and verify research document\n",
    "    file_path = r\"C:\\Users\\j.mundondo\\OneDrive - Statsports\\Desktop\\statsportsdoc\\Projects\\frequency_chat_PH\\data\\multi_session_hias\\Research Paper.docx\"\n",
    "    success = verify_document_loading(file_path)\n",
    "    \n",
    "    if success:\n",
    "        # Test queries\n",
    "        test_queries = [\n",
    "            \"What are Lee's injury risks based on his recent activity pattern?\",\n",
    "            \"Analyze injury risks for Hawk\",\n",
    "            \"What are the injury risks for this player's recent pattern?\"\n",
    "        ]\n",
    "        \n",
    "        for query in test_queries:\n",
    "            print(f\"\\nAnalyzing query: {query}\")\n",
    "            print(\"-\" * 50)\n",
    "            response = analyze_player_risk_streaming(query)\n",
    "            print(\"Analysis Results:\")\n",
    "            print(response[\"answer\"])\n",
    "            print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "footydata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
